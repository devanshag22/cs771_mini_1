{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read emoticon dataset\n",
    "train_emoticon_df = pd.read_csv(\"datasets/train/train_emoticon.csv\")\n",
    "train_emoticon_X = train_emoticon_df['input_emoticon'].tolist()\n",
    "train_emoticon_Y = train_emoticon_df['label'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_emoticon = pd.read_csv(\"datasets/valid/valid_emoticon.csv\")\n",
    "val_emoticon_X = val_emoticon['input_emoticon'].tolist()\n",
    "val_emoticon_Y = val_emoticon['label'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of one-hot encoded data: (7080, 2782)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create a list of all emojis across the dataset\n",
    "emojis = list(set([emoji for sample in train_emoticon_X for emoji in sample]))\n",
    "\n",
    "# Initialize OneHotEncoder with 'handle_unknown' set to 'ignore' to avoid issues with unseen emojis\n",
    "encoder = OneHotEncoder(categories=[emojis]*13, sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# Convert the dataset (each sample is 13 emojis) into a list of lists (2D array)\n",
    "emoji_sequences = [list(sample) for sample in train_emoticon_X]\n",
    "emoji_sequences_val = [list(sample) for sample in val_emoticon_X]\n",
    "\n",
    "# Fit the encoder and transform the data\n",
    "encoded_X = encoder.fit_transform(emoji_sequences)\n",
    "encoded_X_val = encoder.transform(emoji_sequences_val)\n",
    "print(f\"Shape of one-hot encoded data: {encoded_X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train_20, X_test_20, y_train_20, y_test_20 = train_test_split(encoded_X, train_emoticon_Y, test_size=0.8, random_state=42)\n",
    "X_train_40, X_test_40, y_train_40, y_test_40 = train_test_split(encoded_X, train_emoticon_Y, test_size=0.6, random_state=42)\n",
    "X_train_60, X_test_60, y_train_60, y_test_60 = train_test_split(encoded_X, train_emoticon_Y, test_size=0.4, random_state=42)\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(encoded_X, train_emoticon_Y, test_size=0.2, random_state=42)\n",
    "X_train_100 = encoded_X\n",
    "y_train_100 = train_emoticon_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a svm model for binary classification\n",
    "from sklearn.svm import SVC\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "search_space = {\n",
    "    # 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Different kernels to try\n",
    "    'C': (1e-6, 1e+3, 'log-uniform'),                # Regularization parameter\n",
    "    'gamma': (1e-6, 1e+1, 'log-uniform'),            # Kernel coefficient for 'rbf', 'poly' and 'sigmoid'\n",
    "    'degree': (1, 5),                                # Degree of the polynomial kernel (if 'poly' is chosen)\n",
    "    'coef0': (0.0, 10.0)                             # Independent term in 'poly' and 'sigmoid' kernels\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: OrderedDict([('C', 8.56969192382994), ('coef0', 10.0), ('degree', 5), ('gamma', 10.0)])\n",
      "Best cross-validation score: 0.8600282485875705\n",
      "Test set accuracy: 0.8957055214723927\n"
     ]
    }
   ],
   "source": [
    "# Set up the Bayesian optimization with BayesSearchCV\n",
    "bayes_cv_tuner = BayesSearchCV(\n",
    "    estimator=svm,\n",
    "    search_spaces=search_space,\n",
    "    n_iter=32,   # Number of parameter settings that are sampled\n",
    "    cv=5,        # 5-fold cross-validation\n",
    "    random_state=42,\n",
    "    n_jobs=-1    # Use all available cores\n",
    ")\n",
    "\n",
    "bayes_cv_tuner.fit(X_train_100, y_train_100)\n",
    "\n",
    "print(\"Best hyperparameters:\", bayes_cv_tuner.best_params_)\n",
    "print(\"Best cross-validation score:\", bayes_cv_tuner.best_score_)\n",
    "\n",
    "test_accuracy = bayes_cv_tuner.score(encoded_X_val, val_emoticon_Y)\n",
    "print(\"Test set accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
