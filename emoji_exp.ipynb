{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read emoticon dataset\n",
    "train_emoticon_df = pd.read_csv(\"datasets/train/train_emoticon.csv\")\n",
    "train_emoticon_X = train_emoticon_df['input_emoticon'].tolist()\n",
    "train_emoticon_Y = train_emoticon_df['label'].tolist()\n",
    "\n",
    "test_emoticon_X = pd.read_csv(\"datasets/test/test_emoticon.csv\")['input_emoticon'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_emoticon = pd.read_csv(\"datasets/valid/valid_emoticon.csv\")\n",
    "val_emoticon_X = val_emoticon['input_emoticon'].tolist()\n",
    "val_emoticon_Y = val_emoticon['label'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of one-hot encoded data: (7080, 2782)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create a list of all emojis across the dataset\n",
    "emojis = list(set([emoji for sample in train_emoticon_X for emoji in sample]))\n",
    "\n",
    "# Initialize OneHotEncoder with 'handle_unknown' set to 'ignore' to avoid issues with unseen emojis\n",
    "encoder = OneHotEncoder(categories=[emojis]*13, sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# Convert the dataset (each sample is 13 emojis) into a list of lists (2D array)\n",
    "emoji_sequences = [list(sample) for sample in train_emoticon_X]\n",
    "emoji_sequences_val = [list(sample) for sample in val_emoticon_X]\n",
    "\n",
    "# Fit the encoder and transform the data\n",
    "encoded_X = encoder.fit_transform(emoji_sequences)\n",
    "encoded_X_val = encoder.transform(emoji_sequences_val)\n",
    "print(f\"Shape of one-hot encoded data: {encoded_X.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply xgboost model\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the model\n",
    "model = xgb.XGBClassifier(objective='multi:softmax', num_class=2, n_estimators=1000, max_depth=7, learning_rate=0.1, n_jobs=-1)\n",
    "\n",
    "# Train the model\n",
    "model.fit(encoded_X, train_emoticon_Y)\n",
    "\n",
    "# Predict the labels\n",
    "train_predictions = model.predict(encoded_X)\n",
    "val_predictions = model.predict(encoded_X_val)\n",
    "\n",
    "# Calculate the accuracy\n",
    "train_accuracy = accuracy_score(train_emoticon_Y, train_predictions)\n",
    "val_accuracy = accuracy_score(val_emoticon_Y, val_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 5 forms one consisting of 20% of the data 40% of the data 60% of the data 80% of the data and 100% of the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_20, X_test_20, y_train_20, y_test_20 = train_test_split(encoded_X, train_emoticon_Y, test_size=0.8, random_state=42)\n",
    "X_train_40, X_test_40, y_train_40, y_test_40 = train_test_split(encoded_X, train_emoticon_Y, test_size=0.6, random_state=42)\n",
    "X_train_60, X_test_60, y_train_60, y_test_60 = train_test_split(encoded_X, train_emoticon_Y, test_size=0.4, random_state=42)\n",
    "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(encoded_X, train_emoticon_Y, test_size=0.2, random_state=42)\n",
    "X_train_100 = encoded_X\n",
    "y_train_100 = train_emoticon_Y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a neural network model using the one-hot encoded data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Initialize the MLPClassifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 20%: 0.7586912065439673\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "clf.fit(X_train_20, y_train_20)\n",
    "\n",
    "# Predict the labels\n",
    "y_pred = clf.predict(encoded_X_val)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(val_emoticon_Y, y_pred)\n",
    "print(f\"Accuracy for 20%: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 40%: 0.8098159509202454\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "clf.fit(X_train_40, y_train_40)\n",
    "\n",
    "# Predict the labels\n",
    "y_pred = clf.predict(encoded_X_val)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(val_emoticon_Y, y_pred)\n",
    "print(f\"Accuracy for 40%: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 60%: 0.8404907975460123\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_60, y_train_60)\n",
    "y_pred = clf.predict(encoded_X_val)\n",
    "accuracy = accuracy_score(val_emoticon_Y, y_pred)\n",
    "print(f\"Accuracy for 60%: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 80%: 0.8834355828220859\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_80, y_train_80)\n",
    "y_pred = clf.predict(encoded_X_val)\n",
    "accuracy = accuracy_score(val_emoticon_Y, y_pred)\n",
    "print(f\"Accuracy for 80%: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for 100%: 0.901840490797546\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_100, y_train_100)\n",
    "y_pred = clf.predict(encoded_X_val)\n",
    "accuracy = accuracy_score(val_emoticon_Y, y_pred)\n",
    "print(f\"Accuracy for 100%: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [23:54<00:00, 143.45s/trial, best loss: -0.8456214689265537]\n",
      "{'alpha': 0.017995112423157395, 'hidden_layer_sizes': 1}\n"
     ]
    }
   ],
   "source": [
    "# try tpe hyperparameter optimization\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define the search space\n",
    "space = {\n",
    "    'hidden_layer_sizes': hp.choice('hidden_layer_sizes', [(100,), (100, 100), (100, 100, 100)]),\n",
    "    'alpha': hp.uniform('alpha', 0.0001, 0.1)\n",
    "}\n",
    "\n",
    "# Define the objective function\n",
    "def objective(params):\n",
    "    # Initialize the MLPClassifier\n",
    "    clf = MLPClassifier(max_iter=1000, random_state=42, **params)\n",
    "    \n",
    "    # Calculate the cross-validation score\n",
    "    cv_score = cross_val_score(clf, X_train_100, y_train_100, cv=3).mean()\n",
    "    \n",
    "    return -cv_score\n",
    "\n",
    "# Initialize the Trials object\n",
    "trials = Trials()\n",
    "\n",
    "# Run the hyperparameter search\n",
    "best = fmin(objective, space, algo=tpe.suggest, max_evals=10, trials=trials)\n",
    "\n",
    "print(best)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with hyperparameter optimization: 0.9059304703476483\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the best hyperparameters\n",
    "clf = MLPClassifier(max_iter=1000, random_state=42, **best)\n",
    "clf.fit(X_train_100, y_train_100)\n",
    "\n",
    "# Predict the labels\n",
    "y_pred = clf.predict(encoded_X_val)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(val_emoticon_Y, y_pred)\n",
    "print(f\"Accuracy with hyperparameter optimization: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
